{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbc3817cc6804b2f93b8916d8ccce882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5de06702f8ef4b5d96b5b9fda1794cb6"
            ],
            "layout": "IPY_MODEL_8b483469d7964023ab2740101ede5f13"
          }
        },
        "b36cb24cf5c34fe293860519ae5dcc13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0747c757e6024710a3b5e86a60598ab0",
            "placeholder": "​",
            "style": "IPY_MODEL_114c5e2d1bd64c8d9ee5afb3c17b142f",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "c90422a518514b9ea08740fb9ec03951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4c361d90e2f24b05a2236a5112add887",
            "placeholder": "​",
            "style": "IPY_MODEL_d3c9ec979950417faf924721617eaa90",
            "value": "utkarshmittal27"
          }
        },
        "bb1db127b9854619bcaeff4df49e8d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_cc6ac9be22284ddc87b5601b2e1914c8",
            "placeholder": "​",
            "style": "IPY_MODEL_67bcd3be46924b2ebbaee4cfae5b0fc2",
            "value": ""
          }
        },
        "935ddd018ec243c08e8668133ca1fcfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_cf15de7cb6d144e58b001f4631f6c539",
            "style": "IPY_MODEL_8ae5b25784204727a3e0ee7745555c52",
            "tooltip": ""
          }
        },
        "8f488cbab80943e989a61f6378e26019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce001cf74bc427d9ea8b058bc3a3ebc",
            "placeholder": "​",
            "style": "IPY_MODEL_a14c5a646d8f404f8e495ff89533a192",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "8b483469d7964023ab2740101ede5f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0747c757e6024710a3b5e86a60598ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "114c5e2d1bd64c8d9ee5afb3c17b142f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c361d90e2f24b05a2236a5112add887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c9ec979950417faf924721617eaa90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc6ac9be22284ddc87b5601b2e1914c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67bcd3be46924b2ebbaee4cfae5b0fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf15de7cb6d144e58b001f4631f6c539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae5b25784204727a3e0ee7745555c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "cce001cf74bc427d9ea8b058bc3a3ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a14c5a646d8f404f8e495ff89533a192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14d3ac66977d4560acc389e36190bea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b45df876f9ff4dad86a004b3a1bd610b",
            "placeholder": "​",
            "style": "IPY_MODEL_e3828c112700417ea8f48ac331c469c4",
            "value": "Connecting..."
          }
        },
        "b45df876f9ff4dad86a004b3a1bd610b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3828c112700417ea8f48ac331c469c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5de06702f8ef4b5d96b5b9fda1794cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ada69780f5c4ad3952d7c20750e04a0",
            "placeholder": "​",
            "style": "IPY_MODEL_c8d20b1cf61546bfbcd47827ed8f872d",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "6ada69780f5c4ad3952d7c20750e04a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d20b1cf61546bfbcd47827ed8f872d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c74c8f7108da42bfa06da41628303d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4072b2a348743a59f8f51ecc64bad80",
              "IPY_MODEL_dbfce60060cb4951a672c5240cbf6f0e",
              "IPY_MODEL_cb0a9af0871846e6bd22a6d755d7c736"
            ],
            "layout": "IPY_MODEL_faf679cadf3b4d29ba81cf08e75d7d82"
          }
        },
        "c4072b2a348743a59f8f51ecc64bad80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_931112431274447783c17f590a4425df",
            "placeholder": "​",
            "style": "IPY_MODEL_a8d760a3d2334e62a07c3a311f2e5c65",
            "value": "Map: 100%"
          }
        },
        "dbfce60060cb4951a672c5240cbf6f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23de98aaac04304af5b47873533366d",
            "max": 8000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11f2ffe2150a41caba64fa5bce9ca519",
            "value": 8000
          }
        },
        "cb0a9af0871846e6bd22a6d755d7c736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1fcd409ef6f4b2ab15bdec630bbaeb6",
            "placeholder": "​",
            "style": "IPY_MODEL_a2c140b66fe3462cb491f48ce36b7253",
            "value": " 8000/8000 [00:05&lt;00:00, 1597.00 examples/s]"
          }
        },
        "faf679cadf3b4d29ba81cf08e75d7d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931112431274447783c17f590a4425df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d760a3d2334e62a07c3a311f2e5c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e23de98aaac04304af5b47873533366d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f2ffe2150a41caba64fa5bce9ca519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1fcd409ef6f4b2ab15bdec630bbaeb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c140b66fe3462cb491f48ce36b7253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "kagglehub.login()\n",
        "data = kagglehub.competition_download('deep-learning-spring-2025-project-2')\n",
        "print('Data source import complete.')\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import shutil\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "shutil.move(\"/content/kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n",
        "!kaggle competitions download -c deep-learning-spring-2025-project-2\n",
        "!unzip deep-learning-spring-2025-project-2.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "cbc3817cc6804b2f93b8916d8ccce882",
            "b36cb24cf5c34fe293860519ae5dcc13",
            "c90422a518514b9ea08740fb9ec03951",
            "bb1db127b9854619bcaeff4df49e8d4b",
            "935ddd018ec243c08e8668133ca1fcfe",
            "8f488cbab80943e989a61f6378e26019",
            "8b483469d7964023ab2740101ede5f13",
            "0747c757e6024710a3b5e86a60598ab0",
            "114c5e2d1bd64c8d9ee5afb3c17b142f",
            "4c361d90e2f24b05a2236a5112add887",
            "d3c9ec979950417faf924721617eaa90",
            "cc6ac9be22284ddc87b5601b2e1914c8",
            "67bcd3be46924b2ebbaee4cfae5b0fc2",
            "cf15de7cb6d144e58b001f4631f6c539",
            "8ae5b25784204727a3e0ee7745555c52",
            "cce001cf74bc427d9ea8b058bc3a3ebc",
            "a14c5a646d8f404f8e495ff89533a192",
            "14d3ac66977d4560acc389e36190bea4",
            "b45df876f9ff4dad86a004b3a1bd610b",
            "e3828c112700417ea8f48ac331c469c4",
            "5de06702f8ef4b5d96b5b9fda1794cb6",
            "6ada69780f5c4ad3952d7c20750e04a0",
            "c8d20b1cf61546bfbcd47827ed8f872d"
          ]
        },
        "id": "v3aZIbtp5tbZ",
        "outputId": "cf02d080-7a94-4571-f692-e24a16772c57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbc3817cc6804b2f93b8916d8ccce882"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/deep-learning-spring-2025-project-2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.06M/2.06M [00:00<00:00, 4.18MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n",
            "Archive:  deep-learning-spring-2025-project-2.zip\n",
            "  inflating: /content/test_unlabelled.pkl  \n",
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers datasets evaluate accelerate peft bitsandbytes -q\n",
        "!pip3 install nvidia-ml-py3 -q # For GPU monitoring, optional\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikq23Oo_6gPj",
        "outputId": "9e58edb4-35ac-4fee-8523-a907d8ab4c71"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, PeftModel, TaskType # Added TaskType\n",
        "from datasets import load_dataset, Dataset, ClassLabel\n",
        "import evaluate # Use Hugging Face evaluate\n",
        "import pickle\n",
        "# Note: bitsandbytes is imported but used via transformers' from_pretrained arguments\n",
        "\n",
        "# --- Configuration ---\n",
        "BASE_MODEL = 'roberta-base'\n",
        "DATASET_NAME = 'ag_news'\n",
        "OUTPUT_DIR = \"roberta-agnews-lora-results\" # More descriptive name\n",
        "MAX_PARAMETER_LIMIT = 1000000\n",
        "\n",
        "# --- Load Dataset and Tokenizer ---\n",
        "print(f\"Loading dataset: {DATASET_NAME}\")\n",
        "# Load the full training split first\n",
        "dataset = load_dataset(DATASET_NAME, split='train')\n",
        "# Load the actual test split for final unlabelled prediction (if needed later)\n",
        "# test_unlabelled_split = load_dataset(DATASET_NAME, split='test')\n",
        "\n",
        "print(f\"Loading tokenizer for: {BASE_MODEL}\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(BASE_MODEL)\n",
        "\n",
        "# --- Preprocessing ---\n",
        "def preprocess(examples):\n",
        "    # Truncation needed, padding will be handled by DataCollator\n",
        "    tokenized = tokenizer(examples['text'], truncation=True, padding=False, max_length=256) # Adjust max_length if needed\n",
        "    return tokenized\n",
        "\n",
        "print(\"Tokenizing dataset...\")\n",
        "# Apply tokenization (remove original text column)\n",
        "tokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
        "# Rename label column\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "tokenized_dataset.set_format(\"torch\") # Set format early\n",
        "\n",
        "# --- Dataset Info and Split ---\n",
        "num_labels = tokenized_dataset.features['labels'].num_classes\n",
        "class_names = tokenized_dataset.features[\"labels\"].names\n",
        "print(f\"Number of labels: {num_labels}\")\n",
        "print(f\"Label names: {class_names}\")\n",
        "id2label = {i: label for i, label in enumerate(class_names)}\n",
        "label2id = {label: i for i, label in id2label.items()} # Useful for model config\n",
        "\n",
        "import numpy as np\n",
        "token_lengths = [len(x) for x in tokenized_dataset['input_ids']]\n",
        "lower_percentile = 1 # Example: remove shortest 1%\n",
        "upper_percentile = 99 # Example: remove longest 1%\n",
        "lower_thresh = np.percentile(token_lengths, lower_percentile)\n",
        "upper_thresh = np.percentile(token_lengths, upper_percentile)\n",
        "print(f\"Filtering training data: Keeping lengths between {lower_thresh:.0f} and {upper_thresh:.0f} tokens.\")\n",
        "\n",
        "original_size = len(tokenized_dataset)\n",
        "# Ensure you are filtering the dataset object correctly\n",
        "indices_to_keep = [i for i, length in enumerate(token_lengths) if lower_thresh <= length <= upper_thresh]\n",
        "filtered_dataset = tokenized_dataset.select(indices_to_keep)\n",
        "new_size = len(filtered_dataset)\n",
        "print(f\"Filtered dataset size: {new_size} (removed {original_size - new_size} samples)\")\n",
        "\n",
        "# NOW split the filtered_dataset\n",
        "split_datasets = filtered_dataset.train_test_split(test_size=0.1, seed=456)\n",
        "train_dataset = split_datasets['train']\n",
        "eval_dataset = split_datasets['test']\n",
        "# ... continue with training ...\n",
        "\n",
        "# Split the tokenized training set into train and validation\n",
        "# Using a slightly larger validation set might be more robust\n",
        "#split_datasets = tokenized_dataset.train_test_split(test_size=0.1, seed=42) # Example: 10% for validation\n",
        "#train_dataset = split_datasets['train']\n",
        "#eval_dataset = split_datasets['test']\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(eval_dataset)}\")\n",
        "\n",
        "# --- Data Collator ---\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "# --- Load Base Model ---\n",
        "print(f\"Loading base model: {BASE_MODEL}\")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",          # Recommended type: Normalized Float 4\n",
        "    bnb_4bit_compute_dtype=torch.float16 # Use bfloat16 for computation if supported, else torch.float16\n",
        "    # bnb_4bit_use_double_quant=True,    # Optional: Can sometimes improve results slightly\n",
        ")\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    #label2id=label2id,\n",
        "    #quantization_config=bnb_config, # Pass the configuration\n",
        "    # device_map=\"auto\" # Often recommended with quantization for memory balancing across GPUs if >1\n",
        ")\n",
        "\n",
        "# --- Sanity Check: Parameters BEFORE LoRA ---\n",
        "total_params_before = sum(p.numel() for p in model.parameters())\n",
        "trainable_params_before = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\n--- Parameters BEFORE LoRA ---\")\n",
        "print(f\"Total parameters:     {total_params_before:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params_before:,}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# --- LoRA Configuration ---\n",
        "# *** CRITICAL TUNING AREA ***\n",
        "# Adjust 'r' and 'target_modules' to meet the <= 1M trainable parameter constraint\n",
        "# while maximizing performance. Start higher and reduce 'r' if needed.\n",
        "peft_config = LoraConfig(\n",
        "    r=7,                   # Rank (Start higher, e.g., 8, 16, 32, and decrease if over 1M params)\n",
        "    lora_alpha=77,          # Scaling factor (often r*2, but tunable)\n",
        "    lora_dropout=0.01,       # Dropout probability for LoRA layers (0.05 or 0.1 is common)\n",
        "    bias='none',            # Usually 'none' for LoRA\n",
        "    target_modules=[        # Modules to apply LoRA to (check model architecture)\n",
        "        \"query\",\n",
        "        \"value\",\n",
        "         \"key\",            # Optional: Adding key increases params\n",
        "        #\"dense\"           # Optional: Add fully connected layers in attention\n",
        "    ],\n",
        "    task_type=TaskType.SEQ_CLS, # Specify task type\n",
        ")\n",
        "\n",
        "# --- Apply LoRA ---\n",
        "print(\"\\nApplying LoRA configuration...\")\n",
        "peft_model = get_peft_model(model, peft_config)\n",
        "\n",
        "# --- CRITICAL CHECK: Trainable Parameters AFTER LoRA ---\n",
        "peft_model.print_trainable_parameters()\n",
        "trainable_params_after = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
        "print(f\"Calculated Trainable parameters: {trainable_params_after:,}\")\n",
        "\n",
        "if trainable_params_after > MAX_PARAMETER_LIMIT:\n",
        "    print(f\"\\n🚨 WARNING: Trainable parameters ({trainable_params_after:,}) exceed the limit ({MAX_PARAMETER_LIMIT:,})!\")\n",
        "    print(\"🚨 CONSIDER REDUCING 'r' or removing modules from 'target_modules'.\")\n",
        "    # exit() # Uncomment to stop if the constraint is violated\n",
        "else:\n",
        "    print(f\"\\n✅ Trainable parameters ({trainable_params_after:,}) are within the limit ({MAX_PARAMETER_LIMIT:,}).\")\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK-eBugo5viT",
        "outputId": "6b942fb2-eeb5-4954-e4ec-3c403716e1ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset: ag_news\n",
            "Loading tokenizer for: roberta-base\n",
            "Tokenizing dataset...\n",
            "Number of labels: 4\n",
            "Label names: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
            "Filtering training data: Keeping lengths between 26 and 123 tokens.\n",
            "Filtered dataset size: 117675 (removed 2325 samples)\n",
            "Train dataset size: 105907\n",
            "Validation dataset size: 11768\n",
            "Loading base model: roberta-base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Parameters BEFORE LoRA ---\n",
            "Total parameters:     124,648,708\n",
            "Trainable parameters: 124,648,708\n",
            "------------------------------\n",
            "\n",
            "Applying LoRA configuration...\n",
            "trainable params: 980,740 || all params: 125,629,448 || trainable%: 0.7807\n",
            "Calculated Trainable parameters: 980,740\n",
            "\n",
            "✅ Trainable parameters (980,740) are within the limit (1,000,000).\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Ensure predictions are numpy arrays\n",
        "    if isinstance(predictions, tuple): # Sometimes Trainer passes logits and other outputs\n",
        "        predictions = predictions[0]\n",
        "    if isinstance(predictions, torch.Tensor):\n",
        "        predictions = predictions.cpu().numpy()\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "    results = accuracy_metric.compute(predictions=preds, references=labels)\n",
        "    return results # Return dictionary like {'accuracy': 0.95}\n",
        "\n",
        "# --- Training Arguments ---\n",
        "# *** HYPERPARAMETER TUNING AREA ***\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    # --- Key args for accuracy/overfitting ---\n",
        "    learning_rate=3e-5,           # Keep for now, but tunable (3e-5, 8e-5, 1e-4)\n",
        "    num_train_epochs=6,           # TUNED: Reduced epochs (was 6)\n",
        "    optim=\"adamw_torch\",          # CONFIRMED: Use AdamW\n",
        "    weight_decay=0.1,            # CONFIRMED: Standard weight decay\n",
        "    # --- Evaluation / Saving Best ---\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    load_best_model_at_end=True,  # CRITICAL: Use best model found during validation\n",
        "    metric_for_best_model=\"loss\", # Monitor the evaluation loss\n",
        "    greater_is_better=False,   # CRITICAL\n",
        "    # --- Other Args ---\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    fp16=torch.cuda.is_available(), # Use GPU boost\n",
        "    #seed=42,\n",
        "    report_to=\"none\",\n",
        "    lr_scheduler_type='cosine',\n",
        "    gradient_checkpointing_kwargs={'use_reentrant': True}\n",
        "    # ... other args if needed ...\n",
        ")\n",
        "\n",
        "# --- Trainer Setup ---\n",
        "def get_trainer(model):\n",
        "    return Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        compute_metrics=compute_metrics,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,         # Use the validation split for evaluation during training\n",
        "        tokenizer=tokenizer,               # Pass tokenizer for padding/logging\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "peft_lora_finetuning_trainer = get_trainer(peft_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOSgQ8wy52c-",
        "outputId": "712ed13f-37dc-480e-e1e7-27c391ae2967"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2b09f226e9eb>:47: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  return Trainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training ---\n",
        "print(\"\\n--- Starting LoRA Fine-Tuning ---\")\n",
        "train_result = peft_lora_finetuning_trainer.train()\n",
        "print(\"--- Training Finished ---\")\n",
        "\n",
        "# Log training metrics\n",
        "metrics = train_result.metrics\n",
        "peft_lora_finetuning_trainer.log_metrics(\"train\", metrics)\n",
        "peft_lora_finetuning_trainer.save_metrics(\"train\", metrics)\n",
        "peft_lora_finetuning_trainer.save_state() # Saves trainer state\n",
        "\n",
        "# --- Evaluation on Validation Set ---\n",
        "print(\"\\n--- Evaluating Best Model on Validation Set ---\")\n",
        "eval_metrics = peft_lora_finetuning_trainer.evaluate(eval_dataset=eval_dataset) # Use the same eval_dataset\n",
        "peft_lora_finetuning_trainer.log_metrics(\"eval\", eval_metrics)\n",
        "peft_lora_finetuning_trainer.save_metrics(\"eval\", eval_metrics)\n",
        "print(eval_metrics)\n",
        "\n",
        "# --- Save Final Model (Best Adapter) ---\n",
        "# The trainer saves the full checkpoint, but we often only need the adapter\n",
        "best_adapter_path = os.path.join(OUTPUT_DIR, \"best_adapter\")\n",
        "peft_model.save_pretrained(best_adapter_path)\n",
        "print(f\"Best LoRA adapter saved to: {best_adapter_path}\")\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",          # Recommended type: Normalized Float 4\n",
        "#     bnb_4bit_compute_dtype=torch.float16 # Use bfloat16 for computation if supported, else torch.float16\n",
        "#     # bnb_4bit_use_double_quant=True,    # Optional: Can sometimes improve results slightly\n",
        "# )\n",
        "\n",
        "# quantized_model = RobertaForSequenceClassification.from_pretrained(\n",
        "#     BASE_MODEL,\n",
        "#     num_labels=num_labels,\n",
        "#     id2label=id2label,\n",
        "#     label2id=label2id,\n",
        "#     quantization_config=bnb_config,\n",
        "# )\n",
        "\n",
        "# quantized_model = PeftModel.from_pretrained(quantized_model, \"trained_peft_model\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "olBRzmYW55az",
        "outputId": "7079d052-6354-4ee6-c6ba-786e97ede964"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting LoRA Fine-Tuning ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9930' max='9930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9930/9930 1:12:11, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.212700</td>\n",
              "      <td>0.519391</td>\n",
              "      <td>0.872026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.369000</td>\n",
              "      <td>0.302718</td>\n",
              "      <td>0.899048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.323800</td>\n",
              "      <td>0.281137</td>\n",
              "      <td>0.904742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.280800</td>\n",
              "      <td>0.271282</td>\n",
              "      <td>0.910350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.275700</td>\n",
              "      <td>0.262852</td>\n",
              "      <td>0.910945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.260500</td>\n",
              "      <td>0.257747</td>\n",
              "      <td>0.914939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.259300</td>\n",
              "      <td>0.253694</td>\n",
              "      <td>0.916298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.256900</td>\n",
              "      <td>0.250432</td>\n",
              "      <td>0.916893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.264400</td>\n",
              "      <td>0.246753</td>\n",
              "      <td>0.917828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.266600</td>\n",
              "      <td>0.238440</td>\n",
              "      <td>0.919273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.266000</td>\n",
              "      <td>0.235398</td>\n",
              "      <td>0.918933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.251500</td>\n",
              "      <td>0.233081</td>\n",
              "      <td>0.920207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.235100</td>\n",
              "      <td>0.231063</td>\n",
              "      <td>0.921822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.247200</td>\n",
              "      <td>0.228871</td>\n",
              "      <td>0.922842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.249000</td>\n",
              "      <td>0.222727</td>\n",
              "      <td>0.924881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.236900</td>\n",
              "      <td>0.220542</td>\n",
              "      <td>0.925051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.240500</td>\n",
              "      <td>0.227904</td>\n",
              "      <td>0.922842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.231400</td>\n",
              "      <td>0.214943</td>\n",
              "      <td>0.925986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.247500</td>\n",
              "      <td>0.216826</td>\n",
              "      <td>0.924796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.233800</td>\n",
              "      <td>0.212120</td>\n",
              "      <td>0.925816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.218900</td>\n",
              "      <td>0.210624</td>\n",
              "      <td>0.926411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.208900</td>\n",
              "      <td>0.207520</td>\n",
              "      <td>0.929470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.231600</td>\n",
              "      <td>0.202572</td>\n",
              "      <td>0.929385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.210800</td>\n",
              "      <td>0.202691</td>\n",
              "      <td>0.930744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.208900</td>\n",
              "      <td>0.202004</td>\n",
              "      <td>0.931254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.210800</td>\n",
              "      <td>0.203142</td>\n",
              "      <td>0.931849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.207700</td>\n",
              "      <td>0.203491</td>\n",
              "      <td>0.930235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.206900</td>\n",
              "      <td>0.197473</td>\n",
              "      <td>0.933039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.203400</td>\n",
              "      <td>0.195189</td>\n",
              "      <td>0.934228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.204900</td>\n",
              "      <td>0.197303</td>\n",
              "      <td>0.931764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.215800</td>\n",
              "      <td>0.200287</td>\n",
              "      <td>0.929725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.207600</td>\n",
              "      <td>0.195914</td>\n",
              "      <td>0.933039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.187200</td>\n",
              "      <td>0.195173</td>\n",
              "      <td>0.931849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.191300</td>\n",
              "      <td>0.194346</td>\n",
              "      <td>0.934653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.180100</td>\n",
              "      <td>0.195533</td>\n",
              "      <td>0.932954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.192400</td>\n",
              "      <td>0.202241</td>\n",
              "      <td>0.930914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.200900</td>\n",
              "      <td>0.191745</td>\n",
              "      <td>0.934398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.194583</td>\n",
              "      <td>0.933124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.202700</td>\n",
              "      <td>0.191792</td>\n",
              "      <td>0.933294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.200500</td>\n",
              "      <td>0.191694</td>\n",
              "      <td>0.934058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.179300</td>\n",
              "      <td>0.188970</td>\n",
              "      <td>0.934398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.202800</td>\n",
              "      <td>0.186618</td>\n",
              "      <td>0.936353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.182100</td>\n",
              "      <td>0.190422</td>\n",
              "      <td>0.933634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.186900</td>\n",
              "      <td>0.186509</td>\n",
              "      <td>0.934993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.201400</td>\n",
              "      <td>0.188481</td>\n",
              "      <td>0.934398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.192500</td>\n",
              "      <td>0.184700</td>\n",
              "      <td>0.936948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.189100</td>\n",
              "      <td>0.188397</td>\n",
              "      <td>0.934908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.187800</td>\n",
              "      <td>0.188247</td>\n",
              "      <td>0.933719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.205700</td>\n",
              "      <td>0.184193</td>\n",
              "      <td>0.937203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.180100</td>\n",
              "      <td>0.184223</td>\n",
              "      <td>0.937542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.178900</td>\n",
              "      <td>0.182495</td>\n",
              "      <td>0.937712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.174100</td>\n",
              "      <td>0.184724</td>\n",
              "      <td>0.937033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.176600</td>\n",
              "      <td>0.185688</td>\n",
              "      <td>0.937967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.177800</td>\n",
              "      <td>0.187792</td>\n",
              "      <td>0.936438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.177500</td>\n",
              "      <td>0.183203</td>\n",
              "      <td>0.938732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.195200</td>\n",
              "      <td>0.182041</td>\n",
              "      <td>0.938647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.182500</td>\n",
              "      <td>0.185263</td>\n",
              "      <td>0.936608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.190600</td>\n",
              "      <td>0.181996</td>\n",
              "      <td>0.938307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.185200</td>\n",
              "      <td>0.183655</td>\n",
              "      <td>0.937797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.184700</td>\n",
              "      <td>0.182103</td>\n",
              "      <td>0.936778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.179800</td>\n",
              "      <td>0.180722</td>\n",
              "      <td>0.937627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.171000</td>\n",
              "      <td>0.184530</td>\n",
              "      <td>0.937458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.188200</td>\n",
              "      <td>0.185997</td>\n",
              "      <td>0.935588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.185700</td>\n",
              "      <td>0.184002</td>\n",
              "      <td>0.938137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.189500</td>\n",
              "      <td>0.181396</td>\n",
              "      <td>0.938477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.180900</td>\n",
              "      <td>0.180767</td>\n",
              "      <td>0.938732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.164900</td>\n",
              "      <td>0.185787</td>\n",
              "      <td>0.938137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.184700</td>\n",
              "      <td>0.182337</td>\n",
              "      <td>0.938222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.174800</td>\n",
              "      <td>0.179937</td>\n",
              "      <td>0.938562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.177800</td>\n",
              "      <td>0.180770</td>\n",
              "      <td>0.939072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.176600</td>\n",
              "      <td>0.179233</td>\n",
              "      <td>0.938987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.184700</td>\n",
              "      <td>0.179666</td>\n",
              "      <td>0.938732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.178900</td>\n",
              "      <td>0.179555</td>\n",
              "      <td>0.937882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.180300</td>\n",
              "      <td>0.179600</td>\n",
              "      <td>0.938732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.178900</td>\n",
              "      <td>0.178945</td>\n",
              "      <td>0.939072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.168000</td>\n",
              "      <td>0.180697</td>\n",
              "      <td>0.938817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.178200</td>\n",
              "      <td>0.179433</td>\n",
              "      <td>0.939582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.179000</td>\n",
              "      <td>0.178831</td>\n",
              "      <td>0.938307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.176800</td>\n",
              "      <td>0.178533</td>\n",
              "      <td>0.938562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.167500</td>\n",
              "      <td>0.179139</td>\n",
              "      <td>0.938137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.173500</td>\n",
              "      <td>0.178787</td>\n",
              "      <td>0.938817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.179025</td>\n",
              "      <td>0.938902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.162300</td>\n",
              "      <td>0.179321</td>\n",
              "      <td>0.938902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.165200</td>\n",
              "      <td>0.178878</td>\n",
              "      <td>0.939412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.176200</td>\n",
              "      <td>0.178711</td>\n",
              "      <td>0.939157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.167500</td>\n",
              "      <td>0.179024</td>\n",
              "      <td>0.938477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.171500</td>\n",
              "      <td>0.178536</td>\n",
              "      <td>0.938817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.177900</td>\n",
              "      <td>0.178439</td>\n",
              "      <td>0.938477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.169500</td>\n",
              "      <td>0.178856</td>\n",
              "      <td>0.938902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.172900</td>\n",
              "      <td>0.178628</td>\n",
              "      <td>0.938817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.163200</td>\n",
              "      <td>0.178637</td>\n",
              "      <td>0.938902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.164500</td>\n",
              "      <td>0.178539</td>\n",
              "      <td>0.938817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.171100</td>\n",
              "      <td>0.178513</td>\n",
              "      <td>0.938902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.176400</td>\n",
              "      <td>0.178321</td>\n",
              "      <td>0.938647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.189200</td>\n",
              "      <td>0.178279</td>\n",
              "      <td>0.938817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.185300</td>\n",
              "      <td>0.178254</td>\n",
              "      <td>0.938647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>0.178279</td>\n",
              "      <td>0.938647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.170800</td>\n",
              "      <td>0.178290</td>\n",
              "      <td>0.938647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.178279</td>\n",
              "      <td>0.938647</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Finished ---\n",
            "***** train metrics *****\n",
            "  epoch                    =        6.0\n",
            "  total_flos               = 32562158GF\n",
            "  train_loss               =     0.2107\n",
            "  train_runtime            = 1:12:12.08\n",
            "  train_samples_per_second =    146.683\n",
            "  train_steps_per_second   =      2.292\n",
            "\n",
            "--- Evaluating Best Model on Validation Set ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='184' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [184/184 00:18]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        6.0\n",
            "  eval_accuracy           =     0.9388\n",
            "  eval_loss               =     0.1783\n",
            "  eval_runtime            = 0:00:18.28\n",
            "  eval_samples_per_second =    643.531\n",
            "  eval_steps_per_second   =     10.062\n",
            "{'eval_loss': 0.17827866971492767, 'eval_accuracy': 0.938817131203263, 'eval_runtime': 18.2866, 'eval_samples_per_second': 643.531, 'eval_steps_per_second': 10.062, 'epoch': 6.0}\n",
            "Best LoRA adapter saved to: roberta-agnews-lora-results/best_adapter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "udbHLTup57rK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlabelled_pickle_path = \"test_unlabelled.pkl\"\n",
        "unlabelled_df = pd.read_pickle(unlabelled_pickle_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_dataset = Dataset.from_dict({\"text\": unlabelled_df[\"text\"]})\n",
        "\n",
        "# Tokenize function\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=False, max_length=256)\n",
        "\n",
        "# Apply tokenizer\n",
        "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
        "\n",
        "# Create PyTorch DataLoader for batching\n",
        "test_dataloader = DataLoader(tokenized_test_dataset, batch_size=64, collate_fn=data_collator)\n",
        "\n",
        "# Prediction loop\n",
        "#quantized_model.eval()\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()if isinstance(v, torch.Tensor)}\n",
        "        model_inputs = {k: v for k, v in batch.items() if k in tokenizer.model_input_names + [\"attention_mask\"]}\n",
        "        outputs = peft_model(**model_inputs)\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        all_predictions.extend(preds.cpu().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c74c8f7108da42bfa06da41628303d6b",
            "c4072b2a348743a59f8f51ecc64bad80",
            "dbfce60060cb4951a672c5240cbf6f0e",
            "cb0a9af0871846e6bd22a6d755d7c736",
            "faf679cadf3b4d29ba81cf08e75d7d82",
            "931112431274447783c17f590a4425df",
            "a8d760a3d2334e62a07c3a311f2e5c65",
            "e23de98aaac04304af5b47873533366d",
            "11f2ffe2150a41caba64fa5bce9ca519",
            "d1fcd409ef6f4b2ab15bdec630bbaeb6",
            "a2c140b66fe3462cb491f48ce36b7253"
          ]
        },
        "id": "g8PcENJc598s",
        "outputId": "0084316d-e7ac-4c4e-efa2-e374e7b8d009"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c74c8f7108da42bfa06da41628303d6b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    \"ID\": list(range(len(all_predictions))),   # ID ✅\n",
        "    \"label\": all_predictions\n",
        "})\n",
        "df.to_csv(\"submission.csv\", index=False)\n",
        "print(\"✅ Batched predictions complete. Saved to submission.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA6sOMp35_19",
        "outputId": "a221298b-6a7f-4eb0-a968-0e9c119ad4c8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Batched predictions complete. Saved to submission.csv.\n"
          ]
        }
      ]
    }
  ]
}